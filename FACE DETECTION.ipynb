{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190ee254-296a-4ea9-8bc3-b10a8857c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\himan\\appdata\\roaming\\python\\python312\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: dlib in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (19.24.6)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python opencv-python-headless numpy tensorflow dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b52dd6-f7ca-45da-a8c7-e4dfb708cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Model directory not found: Models\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'cap' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 312\u001b[0m\n\u001b[0;32m    309\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 312\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 308\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    309\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'cap' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "class FaceDetector:\n",
    "    # Constants\n",
    "    AGE_BUCKETS = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "    GENDER_BUCKETS = [\"Male\", \"Female\"]\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "    FACE_BLOB_PARAMS = (1.0, (300, 300), [104, 117, 123], True, False)\n",
    "    AGE_GENDER_BLOB_PARAMS = (1.0, (227, 227), (78.426, 87.769, 114.896), True, False)\n",
    "\n",
    "    def __init__(self, model_dir: str = \"Models\", save_dir: str = \"detected_faces\", use_gpu: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the FaceDetector with model paths and configurations.\n",
    "        Args:\n",
    "            model_dir: Directory containing the model files\n",
    "            save_dir: Directory to save detected faces\n",
    "            use_gpu: Whether to use GPU acceleration if available\n",
    "        \"\"\"\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.model_paths = {\n",
    "            'face_model': self.model_dir / \"deploy_face.prototxt.txt\",\n",
    "            'face_weights': self.model_dir / \"res10_300x300_ssd_iter_140000_fp16.caffemodel\",\n",
    "            'age_model': self.model_dir / \"age_net.caffemodel\",\n",
    "            'age_proto': self.model_dir / \"deploy_age.prototxt\",\n",
    "            'gender_model': self.model_dir / \"gender_net.caffemodel\",\n",
    "            'gender_proto': self.model_dir / \"deploy_gender.prototxt.txt\"\n",
    "        }\n",
    "        \n",
    "        self._validate_directories()\n",
    "        self._load_models(use_gpu)\n",
    "        \n",
    "        # Cache for resized faces to avoid repeated allocations\n",
    "        self.face_cache = {}\n",
    "        self.max_cache_size = 100\n",
    "\n",
    "    def _validate_directories(self) -> None:\n",
    "        \"\"\"Validate and create necessary directories.\"\"\"\n",
    "        if not self.model_dir.exists():\n",
    "            raise FileNotFoundError(f\"Model directory not found: {self.model_dir}\")\n",
    "        \n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for name, path in self.model_paths.items():\n",
    "            if not path.is_file():\n",
    "                raise FileNotFoundError(f\"Model file not found: {path} ({name})\")\n",
    "\n",
    "    def _load_models(self, use_gpu: bool) -> None:\n",
    "        \"\"\"Load all required models with optional GPU acceleration.\"\"\"\n",
    "        try:\n",
    "            self.face_net = cv2.dnn.readNetFromCaffe(\n",
    "                str(self.model_paths['face_model']), \n",
    "                str(self.model_paths['face_weights'])\n",
    "            )\n",
    "            self.age_net = cv2.dnn.readNetFromCaffe(\n",
    "                str(self.model_paths['age_proto']), \n",
    "                str(self.model_paths['age_model'])\n",
    "            )\n",
    "            self.gender_net = cv2.dnn.readNetFromCaffe(\n",
    "                str(self.model_paths['gender_proto']), \n",
    "                str(self.model_paths['gender_model'])\n",
    "            )\n",
    "\n",
    "            if use_gpu:\n",
    "                try:\n",
    "                    # Enable GPU acceleration if available\n",
    "                    self.face_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "                    self.face_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "                    self.age_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "                    self.age_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "                    self.gender_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "                    self.gender_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "                    print(\"GPU acceleration enabled\")\n",
    "                except Exception as e:\n",
    "                    print(f\"GPU acceleration not available: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading models: {str(e)}\")\n",
    "\n",
    "    def _get_cached_face(self, face_img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Get or create resized face image from cache.\"\"\"\n",
    "        face_hash = hash(face_img.tobytes())\n",
    "        if face_hash not in self.face_cache:\n",
    "            if len(self.face_cache) >= self.max_cache_size:\n",
    "                self.face_cache.pop(next(iter(self.face_cache)))\n",
    "            self.face_cache[face_hash] = cv2.resize(face_img, (227, 227))\n",
    "        return self.face_cache[face_hash]\n",
    "\n",
    "    def detect_faces(self, frame: np.ndarray) -> List[Tuple[int, int, int, int, float]]:\n",
    "        \"\"\"\n",
    "        Detect faces in the frame and return their coordinates with confidence.\n",
    "        Returns: List of tuples (x, y, x1, y1, confidence)\n",
    "        \"\"\"\n",
    "        face_blob = cv2.dnn.blobFromImage(frame, *self.FACE_BLOB_PARAMS)\n",
    "        self.face_net.setInput(face_blob)\n",
    "        detections = self.face_net.forward()\n",
    "        \n",
    "        faces = []\n",
    "        height, width = frame.shape[:2]\n",
    "        scale = np.array([width, height, width, height])\n",
    "        \n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > self.CONFIDENCE_THRESHOLD:\n",
    "                box = detections[0, 0, i, 3:7] * scale\n",
    "                x, y, x1, y1 = box.astype(\"int\")\n",
    "                # Ensure coordinates are within frame boundaries\n",
    "                x, y = max(0, x), max(0, y)\n",
    "                x1, y1 = min(width, x1), min(height, y1)\n",
    "                faces.append((x, y, x1, y1, confidence))\n",
    "        return faces\n",
    "\n",
    "    def predict_age_gender(self, face_img: np.ndarray) -> Tuple[str, str, float, float]:\n",
    "        \"\"\"\n",
    "        Predict age and gender for a given face image.\n",
    "        Returns: Tuple of (age_group, gender, age_confidence, gender_confidence)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if face_img.size == 0:\n",
    "                return (\"Unknown\", \"Unknown\", 0.0, 0.0)\n",
    "\n",
    "            face_resized = self._get_cached_face(face_img)\n",
    "            \n",
    "            # Single blob creation for both networks\n",
    "            blob = cv2.dnn.blobFromImage(face_resized, *self.AGE_GENDER_BLOB_PARAMS)\n",
    "            \n",
    "            # Age prediction\n",
    "            self.age_net.setInput(blob)\n",
    "            age_preds = self.age_net.forward()\n",
    "            age_idx = np.argmax(age_preds)\n",
    "            age_conf = float(np.max(age_preds))\n",
    "            \n",
    "            # Gender prediction\n",
    "            self.gender_net.setInput(blob)\n",
    "            gender_preds = self.gender_net.forward()\n",
    "            gender_idx = np.argmax(gender_preds)\n",
    "            gender_conf = float(np.max(gender_preds))\n",
    "            \n",
    "            return (\n",
    "                self.AGE_BUCKETS[age_idx],\n",
    "                self.GENDER_BUCKETS[gender_idx],\n",
    "                age_conf,\n",
    "                gender_conf\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error in prediction: {str(e)}\")\n",
    "            return (\"Unknown\", \"Unknown\", 0.0, 0.0)\n",
    "\n",
    "class DetectionLogger:\n",
    "    def __init__(self, output_file: str = \"output_data.csv\"):\n",
    "        \"\"\"Initialize the detection logger with rotating file capability.\"\"\"\n",
    "        self.output_dir = Path(\"logs\")\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        self.base_filename = output_file\n",
    "        self.current_file = self._get_new_logfile()\n",
    "        self._initialize_csv()\n",
    "    \n",
    "    def _get_new_logfile(self) -> Path:\n",
    "        \"\"\"Generate a new logfile name with timestamp.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        return self.output_dir / f\"{timestamp}_{self.base_filename}\"\n",
    "\n",
    "    def _initialize_csv(self) -> None:\n",
    "        \"\"\"Initialize the CSV file with headers.\"\"\"\n",
    "        with open(self.current_file, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                \"Timestamp\", \"Age\", \"Gender\", \"Position\", \n",
    "                \"Age Confidence\", \"Gender Confidence\",\n",
    "                \"Face Confidence\"\n",
    "            ])\n",
    "\n",
    "    def log_detection(self, data: tuple) -> None:\n",
    "        \"\"\"Log a single detection to the CSV file with error handling.\"\"\"\n",
    "        try:\n",
    "            with open(self.current_file, mode=\"a\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error logging detection: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize detector and logger\n",
    "        detector = FaceDetector(use_gpu=True)\n",
    "        logger = DetectionLogger()\n",
    "\n",
    "        # Initialize video capture\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Could not access the camera.\")\n",
    "\n",
    "        # Set optimal camera properties\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "        print(\"Controls:\")\n",
    "        print(\"  'q' - Quit\")\n",
    "        print(\"  's' - Save current frame\")\n",
    "        print(\"  'd' - Toggle detection\")\n",
    "        print(\"  'f' - Toggle fullscreen\")\n",
    "\n",
    "        detection_enabled = True\n",
    "        fullscreen = False\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "        fps = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - start_time\n",
    "            \n",
    "            # Update FPS every half second\n",
    "            if elapsed_time >= 0.5:\n",
    "                fps = frame_count / elapsed_time\n",
    "                frame_count = 0\n",
    "                start_time = current_time\n",
    "            \n",
    "            if detection_enabled:\n",
    "                # Detect faces and predict attributes\n",
    "                faces = detector.detect_faces(frame)\n",
    "                \n",
    "                for (x, y, x1, y1, face_conf) in faces:\n",
    "                    face = frame[y:y1, x:x1]\n",
    "                    if face.size > 0:\n",
    "                        age, gender, age_conf, gender_conf = detector.predict_age_gender(face)\n",
    "                        \n",
    "                        # Draw results with improved visuals\n",
    "                        cv2.rectangle(frame, (x, y), (x1, y1), (255, 0, 0), 2)\n",
    "                        \n",
    "                        # Add background for text\n",
    "                        label = f\"{gender}, {age}\"\n",
    "                        conf_label = f\"Conf: {face_conf:.2f}\"\n",
    "                        \n",
    "                        # Calculate text size for background\n",
    "                        (w1, h1), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                        (w2, h2), _ = cv2.getTextSize(conf_label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                        \n",
    "                        # Draw semi-transparent background\n",
    "                        overlay = frame.copy()\n",
    "                        cv2.rectangle(overlay, (x, y - h1 - 20), (x + max(w1, w2), y), (0, 0, 0), -1)\n",
    "                        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "                        \n",
    "                        # Draw text\n",
    "                        cv2.putText(frame, label, (x, y - h1 - 5),\n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                        cv2.putText(frame, conf_label, (x, y - 5),\n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                        \n",
    "                        # Log detection\n",
    "                        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        logger.log_detection((\n",
    "                            timestamp, age, gender, (x, y, x1, y1),\n",
    "                            age_conf, gender_conf, face_conf\n",
    "                        ))\n",
    "\n",
    "            # Display FPS with background\n",
    "            fps_label = f\"FPS: {fps:.1f}\"\n",
    "            (w, h), _ = cv2.getTextSize(fps_label, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "            cv2.rectangle(frame, (5, 5), (w + 15, h + 15), (0, 0, 0), -1)\n",
    "            cv2.putText(frame, fps_label, (10, h + 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            \n",
    "            # Display frame\n",
    "            window_name = \"Face Detection\"\n",
    "            if fullscreen:\n",
    "                cv2.namedWindow(window_name, cv2.WND_PROP_FULLSCREEN)\n",
    "                cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "            else:\n",
    "                cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "            \n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "            # Handle key presses\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                save_path = Path(\"saved_frames\") / f\"frame_{timestamp}.jpg\"\n",
    "                save_path.parent.mkdir(exist_ok=True)\n",
    "                cv2.imwrite(str(save_path), frame)\n",
    "                print(f\"Frame saved as {save_path}\")\n",
    "            elif key == ord('d'):\n",
    "                detection_enabled = not detection_enabled\n",
    "                print(f\"Detection {'enabled' if detection_enabled else 'disabled'}\")\n",
    "            elif key == ord('f'):\n",
    "                fullscreen = not fullscreen\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db95bee-4ae3-4dfe-ac45-f38156856364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
